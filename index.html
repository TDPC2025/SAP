<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Image Generation from Contextually-Contradictory Prompts</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KBKFF5WPJF"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-KBKFF5WPJF');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Image Generation from Contextually-Contradictory Prompts</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Anonymous authors
            </span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="http://arxiv.org/abs/2506.01929"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/TDPC2025/SAP"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpg">
      <h2 class="subtitle has-text-centered">
	<!-- Introducing <b>''Stage Aware Prompting (SAP)''</b>, a method for resolving contextual contradictions in text-to-image generation by aligning prompt information with the semantic stages of the denoising process. -->
  Text-to-image diffusion models often fail on prompts that combine concepts misaligned with their learned associations, generating semantically inaccurate images. 
  We call this <b>Contextual Contradiction</b>—a failure mode where one concept implicitly contradicts another due to entangled priors. 
  For example, “a bear perfroming a handstand” contradicts the model’s priors about typical bear poses, and “a dragon blowing water” conflicts with its learned association with fire.
      </h2>
      <h3 class="subtitle has-text-centered">
  <!-- Our approach decomposes contextually contradictory prompts into a sequence of proxy prompts, each tailored to a specific timestep range. These stage-aware prompts guide the generation process from coarse layout to fine details, ensuring semantic coherence and mitigating conflicts arising from entangled concept associations in pretrained diffusion models.
  By leveraging a large language model to identify and temporally separate contradictory concepts, SAP enables faithful and fine-grained image generation from prompts that would otherwise fail to align with the intended semantics. -->
  To address this, we introduce <b>''Stage Aware Prompting (SAP)''</b>, a method for resolving contextual contradictions in text-to-image generation by aligning prompt information with the semantic stages of the denoising process. 
  SAP decomposes such prompts into a sequence of <b>proxy prompts</b>, each tailored to a specific timestep range. 
  These stage-aware prompts guide the generation process from coarse layout to fine details. 
  By leveraging a large language model to identify and temporally separate contradictory concepts, SAP enables faithful and fine-grained image generation from prompts that would otherwise fail to align with the intended semantics.
</h3>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel" data-slides-to-show="1">
          <img src="static/images/results/shrek.jpeg">
          <img src="static/images/results/monkey.jpeg">
          <img src="static/images/results/storm.jpeg">
          <img src="static/images/results/boxer.jpeg">
          <img src="static/images/results/skyscraper.jpeg">
          <img src="static/images/results/jetski.jpeg">
          <img src="static/images/results/piggyback.jpeg">
          <img src="static/images/results/spongebob.jpeg">
          <img src="static/images/results/hive.jpeg">
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-image diffusion models excel at generating high-quality, diverse images from natural language prompts. 
            However, they often fail to produce semantically accurate results when the prompt contains concept combinations that contradict their learned priors.
            We define this failure mode as <em>contextual contradiction</em>, where one concept implicitly negates another due to entangled associations learned during training.
            To address this, we propose a stage-aware prompt decomposition framework that guides the denoising process using a sequence of proxy prompts. 
            Each proxy prompt is constructed to match the semantic content expected to emerge at a specific stage of denoising, while ensuring contextual coherence.
            To construct these proxy prompts, we leverage a large language model (LLM) to analyze the target prompt, identify contradictions, and generate alternative expressions that preserve the original intent while resolving contextual conflicts.
            By aligning prompt information with the denoising progression, our method enables fine-grained semantic control and accurate image generation in the presence of contextual contradictions. Experiments across a variety of challenging prompts show substantial improvements in alignment to the textual prompt.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->

    <!--/ Paper video. -->
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
      <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3"> Coarse-to-fine denoising</h2>
          <div class="content has-text-justified">
            <p>
              Text-to-image diffusion models generates images by progressively refining noise over a series of denoising steps. 
              This process inherently follows a coarse-to-fine structure: early steps establish broad layout and spatial composition, while later steps gradually add fine details.
              This generative structure gives rise to two key observations:
            <ul style="text-align: left; display: inline-block;">
              <li><strong>Irreversibility of details:</strong> At each stage of denoising, the model commits to a certain level of structural detail. Once a given attribute (e.g., layout, coarse shape) has been established, it becomes effectively fixed and cannot be revised in later steps, even if it misaligns with the prompt.</li>
              <li><strong>Flexibility in high-frequency details:</strong> In early stages, high-frequency details have not yet emerged and thus are unaffected by the prompt. This allows greater flexibility in guiding the model without impacting the final generated fine details.</li>
            </ul>
            </p>
          </div>
          <img class="my-image" src="static/images/coarse_to_fine.jpg">
          <div class="content has-text-justified">
            <p>
		          Here, we display this behaviour by observing the model x<sub>0</sub> prediction through various denoising steps.
              <ul>
                <li><strong>Top row:</strong> Using the full prompt from the start causes early mistakes (like night scenes) that can't be fixed later.</li>
                <li><strong>Middle row:</strong> A clean proxy prompt avoids early conflicts, and switching mid-way keeps the layout while correcting details.</li>
                <li><strong>Bottom row:</strong> A bad proxy misguides structure and lighting.</li>
              </ul>
            </p>
          <p>
              These insights enable our method to steer the generation process more effectively by conditioning the model with prompt information that aligns with what the model is capable of expressing at each stage.
              </p>
          </div>
    </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
      <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">How does it work?</h2>
          <!-- <img class="my-image" src="static/images/layouts.jpg" style="width:600px; height:auto;"> -->
          <div class="content has-text-justified">
            <p>
              Our method guides the denoising process using time-dependent proxy prompts that adapt to the model’s internal progression from coarse to fine.

              A large language model (LLM) analyzes the input prompt and decomposes it into a sequence of proxy prompts, each tailored to specific stages of the generation process. These intermediate prompts are injected into the diffusion model at predefined timestep intervals.
              
              By aligning the prompt information with the model’s evolving visual structure, this stage-aware conditioning ensures a semantically coherent and contextually accurate image.
              
              
            </p>
          </div>
          <img class="my-image" src="static/images/overview.jpg" style="width:1000px; height:auto;">
          <div class="content has-text-justified">
            <!-- <p>
              Our method navigates the denoising process using time-dependent proxy prompts. 
              (Top) A large language model (LLM) is employed to decompose a target prompt with entangled or conflicting attributes into a sequence of proxy prompts and their corresponding time-step intervals. 
              (Bottom) These intermediate prompts are injected into the diffusion process at the specified intervals. 
              This time-dependent prompt conditioning aligns more closely with the model’s prior at each stage, enabling a semantically consistent and temporally coherent progression through the denoising process.
            </p> -->
          </div>
      </div>
  </div>
</section>


<section class="section is-light" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website source code based on the <a href="https://nerfies.github.io/">Nerfies</a> project page. If you want to reuse their <a href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>